\chapter{Related Work}
\label{sec:rw}
In this chapter, we survey the existing relevant research in the topic area of this thesis. 
We present the fundamental research and newer data-driven developments in the related fields of instruction scheduling (\Cref{sec:rw:instruction-scheduling}) and register allocation (\Cref{sec:rw:register-allocation}).
Further, we discuss some other relevant works in the fields of machine learning based compiler optimizations, runtime estimation, code feature extraction and machine learning approaches on other scheduling tasks (\Cref{sec:rw:other}).

\section{Instruction Scheduling}
\label{sec:rw:instruction-scheduling}
\subsection{Classical Approaches}
Scheduling problems appear in many fields.
This is why general scheduling is a topic with much existing research.
Also the research on instruction scheduling has a long history.

Algorithms exist that can generate perfect instruction schedules for simple situations with perfect information.
The requirements are met for architectures with only one functional unit and uniform instruction latencies.
The best-known algorithms in this field is the Sethi-Ullman labelling algorithm~\cite{sethi1970generation} and the work by \citeauthor{proebsting1991linear}~\cite{proebsting1991linear}.

However, these conditions are not present in modern processors.
In more complex situations, the instruction scheduling problem is NP-complex~\cite{hennessy1983postpass}.
Modern processors use pipelines to achieve instruction parallelism, see \Cref{sec:bg:cpu}.
Consequently, most instruction schedulers that are used nowadays are based on the list scheduling framework, which was proposed by \citeauthor{landskov1980local}~\cite{landskov1980local}.
The algorithms, that follow this approach, are better able to generate instruction schedules for pipelined processors.
\citeauthor{heller1961sequencing}~\cite{heller1961sequencing} published an early work on how to approach instruction scheduling for these processors.
Much research on further developments of the list scheduling was published~\cite{bernstein1991global,gibbons1986efficient,hennessy1983postpass}.

As elaborated in \Cref{sec:bg:cpu}, the available information on instruction latencies is mostly uncertain.
The reasons are instruction-level parallelism and uncertain memory latencies.
One way to approach this problem, is balanced scheduling~\cite{kerns1993balanced,lo1995improving}.
Another proposed idea, was to use stochastic instruction scheduling~\cite{schielke2000stochastic}.

Instruction scheduling typically works on a basic block level.
This also means that transitions between basic blocks are not scheduled to work well together.
However, research exists on extending the scope to greater regions~\cite{fisher1981trace,bernstein1991global,hwu1993superblock}.

\subsection{Machine Learning Approaches}
The first work that combined data-driven methods with instruction scheduling was a patent by \citeauthor{tarsy1994method}~\cite{tarsy1994method}, filed in \citeyear{tarsy1994method}.
They optimize weights that are used in cost-based heuristics.
These heuristics are used in list scheduling for pipelined processors.

List schedulers usually have multiple heuristics that are used for choosing an instruction from the list of available instructions.
The selection is based on a weighted sum of the heuristics.
\citeauthor{beaty1996using}~\cite{beaty1996using} published a work in \citeyear{beaty1996using}, in which they have used a genetic algorithm to learn weights for different heuristics.
They achieved a 5\% performance increase compared to a random scheduler on three architectures.

\citeauthor{moss1997learning}~\cite{moss1997learning} trained a function that would prefer one instruction over another when presented the previosuly scheduled instructions.
They used decision trees, look-up tables, ELF function approximations, and feed-forward neural networks.
The decision tree performed best and found often the optimal schedule.
However, they only used simulations and limited the basic block length to 10 instructions.

A reinforcement learning and a search heuristic were proposed by \citeauthor{mcgovern1999scheduling}~\cite{mcgovern1999scheduling,mcgovern2002building}.
Their reinforcement learning heuristic sometimes found a better instruction schedule than their baseline.
The long-running search approach found a better instruction schedule every time.
However, their baseline was only a random instruction scheduler and they have only used simulation results.

\citeauthor{russell2006learning}~\cite{russell2006learning} used decision trees to create heuristics to improve instruction scheduling decisions.
They showed, that they generated better instruction schedules 7.8 times more often than the compared heuristics.
Their results are also based on simulations only.

A newer work in this field was published by \citeauthor{jain2019learning}~\cite{jain2019learning}.
They trained a neural network to imitate the instruction schedules by the GCC compiler.
However, this approach is limited by the performance of the GCC instruction scheduler and cannot exceed it.

We conclude, that the machine learning based approaches mostly performed well in theory, but only against weak random baselines.
The only work, that we found that was evaluated on hardware was~\cite{beaty1996using}.

% \citeauthor{cavazos2004inducing} showed that instruction scheduling only makes a difference on some basic blocks.
% They used decision trees for selecting basic blocks for instruction scheduling~\cite{cavazos2004inducing}.

\section{Register Allocation}
\label{sec:rw:register-allocation}
We have disussed the implications of the instruction scheduling phase on the register allocation \Cref{sec:bg:compilers:backend}.
This interdependence was also shown by \citeauthor{goodman1988code}~\cite{goodman1988code}.
\citeauthor{lavrov1962store} showed the connection between the graph-coloring problem and register allocation and thus, the NP-completeness~\cite{lavrov1962store}.
The first graph-coloring based algorithm implemented in a compiler by \citeauthor{chaitin1982register}~\cite{chaitin1982register}.

In the field of register allocation also appeared research that builds the connection to data-driven methods.
\citeauthor{das2019deep} used a deep learning approach to solve the graph coloring problem~\cite{das2019deep}.
The newer and naturally better fitting approach with graph neural networks was used by \citeauthor{lemos2019graph}~\cite{lemos2019graph} to solve the graph coloring problem. 

\section{Other}
\label{sec:rw:other}
\subsection{Compiler Optimizations with Machine Learning}
% \cite{mammadli2020static,haj2020neurovectorizer,huang2019autophase,qiao2019loop}
Machine learning approaches are also applied to optimize other parts of the compilation process.
Deep reinforcement learning was successfully applied to the phase-ordering problem by \citeauthor{mammadli2020static}~\cite{mammadli2020static} and \citeauthor{huang2019autophase}~\cite{huang2019autophase}.
Phase-ordering means to select the compilers optimization passes and define its execution order (see \Cref{sec:bg:compilers:optimizer} for information on the optimization phase).
Deep reinforcement learning was also used by \citeauthor{haj2020neurovectorizer}~\cite{haj2020neurovectorizer} to translate loops into vector processing instructions (SIMD).
\citeauthor{wang2009mapping}~\cite{wang2009mapping} used machine learning to predict the optimal number of threads and the optimal scheduling policy for OpenMP parallelized loops.
For more works, see the surveys~\cite{wang2018machine,ashouri2018survey}.

\subsection{Runtime Estimation}
Various tools for throughput and runtime estimation exist, like Ithemal~\cite{mendis2019ithemal}, llvm-mca\footnote{https://llvm.org/docs/CommandGuide/llvm-mca.html}, and Intel Architecture Code Analyzer (IACA)\footnote{https://software.intel.com/content/www/us/en/develop/articles/intel-architecture-code-analyzer.html}.
However, the listed tools only work with the x86 architecture, which we do not use.
Especially the Ithemal~\cite{mendis2019ithemal} project is interesting as they use a neural network to predict the runtime from the basic block.
That means they learned to extract features from the basic block to predict its runtime.
% This could also be interesting in the instruction scheduling task.

% Code representation learning
\subsection{Feature Extraction from Code}
% \cite{ben2018neural,cummins2021programl,brauckmann2020compiler}
The previously cited works on data-driven machine learning optimizations have or might benefit from research whose goal it is to automatically extract features from code.
A similar approach to the word2vec~\cite{mikolov2013efficient} approach in the \ac{nlp} area was proposed by~\cite{ben2018neural,alon2019code2vec}.
\citeauthor{cummins2021programl} developed a method to extract features from code, that is based on graph structures~\cite{cummins2021programl}.
The work proposed by \citeauthor{brauckmann2020compiler}~\cite{brauckmann2020compiler} works similarly, they also work on graph structures and use graph neural networks to extract features.

\subsection{Other Scheduling Tasks with Machine Learning}
\citeauthor{mao2019learning}~\cite{mao2019learning} have used a deep reinforcement learning approach to schedule data-processing jobs onto compute clusters.
This work is interesting because the jobs have dependencies on each other which are represented in a \ac{dag}, just like the instructions in the instruction scheduling problem.

% \subsection*{Register Allocation for Intel Processor Graphics}\cite{chen2018register}

% \section{Compiler Optimization Phase Ordering}
% %Static neural compiler optimization via deep reinforcement learning~\cite{mammadli2020static}\\
% % - Uses only static information extracted from IR 
% % - IR embedded by using ben2018neural
% % - Use deep q learning
% % - training is executed by running the modified IR and measure the speedup 
% % - reward is defined as ln(T(s_t)/T(s_t+1)) with T being the runtime


% \subsection*{Autophase: Compiler phase-ordering for hls with deep reinforcement learning}\cite{huang2019autophase}

% \section{Code Representation}
% \label{sec:rw:code-representation}
% For making use of data driven techniques in the area of compiler optimization, it is required to somehow extract features from the code to make it accessible for data driven algorithms.
% Older works usually made use of approaches that used hand-tuned features.
% \todo{Maybe add references used in https://chriscummins.cc/u/ed/phd-thesis.pdf (3.3.2.1)}

% Recent works are inspired by the advances in the the field of \ac{nlp}, which are caused by neural networks and continuous distributed vectors (referred to as embeddings) \eg, word2vec~\cite{mikolov2013efficient}. 
% Although, human language is different from codes of programming languages in many aspects, embeddings prove to be useful in code related tasks, too.

% Code inputs may be used directly in a high-level programming language or in an \ac{ir} (\eg, LLVM-IR~\cite{LLVM:CGO04}).
% The advantage of using an \ac{ir} is that it is independent of the source programming language and the target architecture.

%Overviews:
%\begin{itemize}
%    \item ProGraML Paper under Motivation
%    \item https://chriscummins.cc/u/ed/phd-thesis.pdf (3.3.2.1)
%    \item https://arxiv.org/pdf/1904.03061.pdf
%\end{itemize}

% Most approaches for representing high-level language code use some sort of the \ac{ast} in combination with various learning mechanisms.
% %code2vec: Learning distributed representations of code \cite{alon2019code2vec}
% % - works on source code
% % - sensitive to identifier names
% \citeauthor{alon2019code2vec}~\cite{alon2019code2vec} used paths of the \ac{ast} in combination with a Attention Neural Network model.
% Others have used the \ac{ast} in combination with Gated Graph Neural Networks~\cite{ye2020deep, allamanis2017learning}, with Support Vector Machines~\cite{park2012using} or with \ac{lstm} Networks for tree structures~\cite{dam2018deep}.
%\cite{ye2020deep} % Deep Program Structure Modeling Through Multi-RelationalGraph-based Learning, graph-based deep learning (Gated Graph Neural Networks), AST
%\cite{allamanis2017learning} % LEARNING  TO REPRESENT PROGRAMS WITH GRAPHS, graph-based deep learning (Gated Graph Neural Networks), AST
%\cite{dam2018deep} % A deep tree-based model for software defect prediction, AST, tree-LSTM
%\cite{park2012using} % Using Graph-Based ProgramCharacterization for Predictive Modeling, SVM

% \subsubsection{Neural code comprehension: A learnable representation of code semantics~\cite{ben2018neural}}
% - Defines embedding space inst2vec
% - Encodes LLVM-IR, independent of source programming language
% - Leveraging data- and control flow (Contextual Flow Graphs)
% - Use RNN
% - Analyze the embeddings qualitatively using analogies and clustering, and evaluate the learned representation on three different high-level tasks
% - See description in ProGraML Paper under Motivation
% With Neural Code Comprehension (inst2vec)~\cite{ben2018neural}, Ben-Nun et al. defined an embedding space for the LLVM-IR.
% Relevant information to discover code semantics are data and control flow. 
% To emphasize the semantics, the data and control flow are represented in a novel graph structure, called \acp{xfg}.
% %Before building the \ac{xfg}, the LLVM-IR code is split into basic blocks, so diverging control flow is eliminated.
% The context of an individual statement, with size $N$, is defined as the statement and its graph neighbors that are connected by a path of length $N$.
% This statement is then mapped to its embedding by using the skip-gram model~\cite{mikolov2013distributed}, which are known to work good in \ac{nlp} tasks.
% The \ac{xfg} captures features like data and control dependence's, instructions and data types, which are important for our task.

% \subsection*{ProGraML: Graph-based Deep Learning for Program Optimization and Analysis}\cite{cummins2021programl}
%\begin{itemize}
%    \item approach is insensitive to identifier names and preserves operand order and type information
%    \item compared to inst2vec, it can do the same plus preserve operand order, important to distinguish non-commutative ops
%    \item represent programs as directed multigraphs where statements, identifiers, and immediate values are vertices, and relations between vertices are edge
%    \item encode IR into a graph which will be consumed by a Message Passing Neural Network to execute some task
%\end{itemize}

% \subsection*{Compiler-based graph representations for deep learning models of code}\cite{brauckmann2020compiler}
% \todo{Find Paper PDF and write text}

%IR2Vec: A Flow Analysis based Scalable Infrastructure for Program Encodings \cite{keerthy2019ir2vec}
%\begin{itemize}
%    \item Abstracts away the width of the datatype
%\end{itemize}
% IR2Vec~\cite{keerthy2019ir2vec} is another approach that maps an \ac{ir} to a embedding space.
% However, the datatype size, which is important for code optimizations, is abstracted away during the embedding process.

% \section{Applied Machine Learning on Code}
% \label{sec:rw:applied-code-ml}
% Machine learning approaches are used in newer research for code analysis and for compiler optimizations.
% Before machine learning algorithms can be applied, the code must be transformed into some format that the algorithm can consume.

% Various approaches exist that are inspired by the advances in the \ac{nlp} field.
% Much success in the \ac{nlp} field is based on word embeddings~\cite{mikolov2013efficient}.
% Embeddings map words into a high-dimensional continous vector space, such that words with a similar meaning are close to each other.
% \citeauthor{alon2019code2vec}~\cite{alon2019code2vec} used paths of the \ac{ast} in combination with a Attention Neural Network model to map Java code snippets into an embedding space.
% A more broadly applicable approach is to map from instructions of the LLVM \ac{ir} into an embedding space, because it is independent of the source programming language and the target hardware architecture.
% A recent work, that implements this mapping is from \citeauthor{venkatakeerthy2020ir2vec}~\cite{venkatakeerthy2020ir2vec}.
% This mapping from LLVM \ac{ir} was also proposed by \citeauthor{ben2018neural}~\cite{ben2018neural}. 
% Their work led to the improved work of \citeauthor{cummins2021programl}~\cite{cummins2021programl}.


% \subsection*{Ithemal Accurate, portable and fast basic block throughput estimation using deep neural networks}\cite{mendis2019ithemal}
% \subsection*{NeuroVectorizer: End-to-End Vectorization with DeepReinforcement Learning}\cite{haj2020neurovectorizer}
% \subsection*{From Loop Fusion to Kernel Fusion: A Domain-Specific Approach to Locality Optimization}\cite{qiao2019loop}
% \subsection*{A Machine Learning Approach for Performance Prediction and Scheduling on Heterogeneous CPUs}\cite{nemirovsky2017machine}



