\chapter{Conclusion and Future Work}
\label{sec:conclusion}
In this last chapter, we summarize our work, outline the contributions and results.
Further, we present possible research directions that this thesis opens.

% Answer the research questions
% how good the instruction schedules are that state-of-the-art compilers generate and if we can find better ones
We showed that state-of-the-art compilers do not generate optimal instruction schedules.
With a search approach we are able to find better performing instruction schedules in many cases.
% if it is possible to train a model that can generate better instruction schedules than modern compilers
Further, we showed that it is possible to train a supervised model that is able to generate better instruction schedules than modern compilers.
% investigate the varying influence of the instruction schedules on the performance of in-order and out-of-order processors
In our experiments we have seen that compile-time instruction scheduling has a lower influence on the benchmark runtime on out-of-order processors than on in-order processors.

% Show how you have addressed your aims and objectives
In order to build a methodology that generates optimized instruction schedulers for any novel hardware, we have built our approach on top of the LLVM compiler framework.
We propose an approach that first searches for well performing instruction schedules for a set of of basic block benchmarks.
The search is takes too much time to do it at compile-time.
Therefore, we build a dataset with the evaluated basic blocks.
To have a fast instruction scheduler, we use this dataset to train a supervised model.

% Explain the significance and implications of your findings
With our approach it is possible to reduce the runtime of compiled computer programs on any hardware.
This is especially true for in-order architectures.
Cheaper processors, that are widely used in mobile and edge devices, and also accelerators like \acp{gpu} implement in-order architectures.
Shorter runtimes are a good achievement, but with shorter runtimes also comes a reduced energy consumption which is especially important for devices that are powered by batteries.

% Explain the contribution the study makes
Our contribution is a pipeline that automatically optimizes instruction schedulers for any hardware.
Therefore, we developed metrics to select basic blocks with a high influence on the overall runtime of the program.
We extract these basic blocks to execute them in our runtime measurement framework.
The selected and extracted basic blocks are used in an \ac{mcts} approach to find well performing instruction schedules for each basic block.
As a consequence, we get many evaluated scheduling decisions.
We use them to build a datset for training supervised models that can generate well performing instruction schedules for unknwon basic blocks.
Additionally, we made a feasibility study, that showed the potential of optimizing instruction schedulers.

% Explain the limitations of the study
While our work performs well on the in-order architecture, the results are not that good on out-of-order processors.
The search for well performing instruction schedules achieves an average runtime speed up of 0.3\%.
This is still a speed up on its own, but is also an upper limit for the supervised learning models which all perform worse than modern compilers.
 
% Lay out questions for further research
Our research layed out multiple directions in which future work could go.
We used in our search and supervised learning models only basic information that are present in the \ac{dag}.
The LLVM compiler also provides hardware-independent analysis passes that provide deeper information.
These informations could be used to improve the approach, especially the learning models.
The supervised learning models are also still limited and basic models.
Imaginable is the usage of graph neural networks for \ac{dag} analysis, the usage of embedding techniques that we have discussed in the literature review, and more elaborated machine learning approaches in general.



% \section{Future Work}

% Nutze mehr Informationen über die Instructions in schedules
% Graph based learning to learn mapping from DAG to schedule
% Learn embeddings word2vec


% What we did is train a heuristic for list scheduling with limited information about the DAG. Our scheduler only learns from ready-to-schedule nodes . It would be interesting to train a graph-nn to analyze the DAG and use it as a single list scheduling heuristic. -> See SAGE Collegeblock Rückseite von Meeting 1.10.
% Include discussion about graph embeddings and put references here
% \cite{mao2019learning}


